# ğŸ“ NLP Model for Sentiment Analysis

Este repositorio contiene un proyecto de Procesamiento de Lenguaje Natural (NLP) desarrollado como parte de una asignatura. El objetivo fue entrenar un modelo capaz de detectar **reseÃ±as negativas** a partir de un conjunto de opiniones de clientes.

## ğŸ“Œ Project Overview

- **Objetivo**: Clasificar las reseÃ±as de clientes como negativas o no.
- **Reto**: El conjunto de datos tenÃ­a **clases desbalanceadas**, con menos reseÃ±as negativas que positivas.
- **Enfoque**: Comparar el rendimiento de diferentes modelos y tÃ©cnicas de preprocesamiento ante este desequilibrio.

## âš™ï¸ Methods and Tools

- Modelos utilizados: `Logistic Regression`, `Random Forest`
- TÃ©cnicas aplicadas:
  - Uso del parÃ¡metro `class_weight='balanced'` para tratar el desbalanceo
  - EliminaciÃ³n de palabras vacÃ­as estÃ¡ndar (se mantuvieron negaciones como _not_, _no_, _didn't_)
  - EvaluaciÃ³n de los modelos con foco en la detecciÃ³n de **reseÃ±as negativas**

## ğŸ“Š Key Conclusions

- âœ… **Manejo del desbalanceo**:  
  Es mÃ¡s efectivo usar la opciÃ³n `class_weight='balanced'` dentro de los modelos que aplicar tÃ©cnicas de muestreo manualmente.

- ğŸ§¹ **Stop words**:  
  Eliminar palabras vacÃ­as personalizadas (como _not_, _no_, _didn't_) **no mejorÃ³** los resultados. Solo se eliminaron las stop words estÃ¡ndar.

- âš–ï¸ **Rendimiento del modelo**:  
  No existe una soluciÃ³n perfecta. La elecciÃ³n depende del objetivo del problema: minimizar **falsos negativos** o **falsos positivos** segÃºn el contexto.

- ğŸ” **RegresiÃ³n logÃ­stica vs. Random Forest**:  
  Tras entrenar ambos modelos con el dataset completo y desbalanceado utilizando `class_weight='balanced'`:
  - La **RegresiÃ³n LogÃ­stica** tuvo mejores resultados en la detecciÃ³n de **reseÃ±as negativas**
  - Esto la convierte en una opciÃ³n interesante para empresas que quieran identificar opiniones negativas y actuar en consecuencia.

## ğŸ”® Future Improvements

- ğŸ› ï¸ Aplicar **GridSearchCV** para optimizar los hiperparÃ¡metros del modelo Random Forest.
- ğŸ¤– Explorar enfoques de **Deep Learning**, como **BERT** u otros modelos basados en transformers, para capturar patrones mÃ¡s complejos en el lenguaje.

